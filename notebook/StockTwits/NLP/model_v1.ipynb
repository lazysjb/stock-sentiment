{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import funcy\n",
    "\n",
    "from config import STOCKTWITS_TICKER_LIST\n",
    "from util.file_util import StockTwitsFileReader\n",
    "from nlp.twokenize import normalizeTextForTagger, tokenize\n",
    "from nlp.text_processor import (\n",
    "    token_is_cash_tag, token_is_punct, token_matches_ticker, twit_tokenize\n",
    ")\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_twits_reader = StockTwitsFileReader()\n",
    "\n",
    "data_dir = os.path.join(stock_twits_reader.root_dir,\n",
    "                        'processed/text_analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "twit_train_df = pd.read_pickle(os.path.join(data_dir,\n",
    "                                            'train_twits.pkl'))\n",
    "twit_val_df = pd.read_pickle(os.path.join(data_dir,\n",
    "                                          'val_twits.pkl'))\n",
    "twit_test_df = pd.read_pickle(os.path.join(data_dir,\n",
    "                                          'test_twits.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((314276, 7), (78570, 7), (98212, 7))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twit_train_df.shape, twit_val_df.shape, twit_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_est</th>\n",
       "      <th>created_at_est</th>\n",
       "      <th>body</th>\n",
       "      <th>symbols</th>\n",
       "      <th>entities.sentiment.basic</th>\n",
       "      <th>links</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53193</th>\n",
       "      <td>2018-12-06</td>\n",
       "      <td>2018-12-06 16:53:51</td>\n",
       "      <td>$MSFT   .</td>\n",
       "      <td>[{'id': 2735, 'symbol': 'MSFT', 'title': 'Micr...</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>None</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610784</th>\n",
       "      <td>2019-07-11</td>\n",
       "      <td>2019-07-11 10:19:04</td>\n",
       "      <td>$TSLA $400 is coming</td>\n",
       "      <td>[{'id': 8660, 'symbol': 'TSLA', 'title': 'Tesl...</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>None</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571364</th>\n",
       "      <td>2019-06-05</td>\n",
       "      <td>2019-06-05 17:49:20</td>\n",
       "      <td>$TSLA they are just so beautiful looking on th...</td>\n",
       "      <td>[{'id': 8660, 'symbol': 'TSLA', 'title': 'Tesl...</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>None</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8447</th>\n",
       "      <td>2019-05-13</td>\n",
       "      <td>2019-05-13 10:20:45</td>\n",
       "      <td>$UBER I guess Saudis long algos are activated ...</td>\n",
       "      <td>[{'id': 11554, 'symbol': 'UBER', 'title': 'Ube...</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>None</td>\n",
       "      <td>UBER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70872</th>\n",
       "      <td>2018-05-03</td>\n",
       "      <td>2018-05-03 09:13:28</td>\n",
       "      <td>$TSLA wow poor bulls that have been buying the...</td>\n",
       "      <td>[{'id': 8660, 'symbol': 'TSLA', 'title': 'Tesl...</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>None</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date_est       created_at_est  \\\n",
       "53193   2018-12-06  2018-12-06 16:53:51   \n",
       "610784  2019-07-11  2019-07-11 10:19:04   \n",
       "571364  2019-06-05  2019-06-05 17:49:20   \n",
       "8447    2019-05-13  2019-05-13 10:20:45   \n",
       "70872   2018-05-03  2018-05-03 09:13:28   \n",
       "\n",
       "                                                     body  \\\n",
       "53193                                           $MSFT   .   \n",
       "610784                               $TSLA $400 is coming   \n",
       "571364  $TSLA they are just so beautiful looking on th...   \n",
       "8447    $UBER I guess Saudis long algos are activated ...   \n",
       "70872   $TSLA wow poor bulls that have been buying the...   \n",
       "\n",
       "                                                  symbols  \\\n",
       "53193   [{'id': 2735, 'symbol': 'MSFT', 'title': 'Micr...   \n",
       "610784  [{'id': 8660, 'symbol': 'TSLA', 'title': 'Tesl...   \n",
       "571364  [{'id': 8660, 'symbol': 'TSLA', 'title': 'Tesl...   \n",
       "8447    [{'id': 11554, 'symbol': 'UBER', 'title': 'Ube...   \n",
       "70872   [{'id': 8660, 'symbol': 'TSLA', 'title': 'Tesl...   \n",
       "\n",
       "       entities.sentiment.basic links ticker  \n",
       "53193                   Bullish  None   MSFT  \n",
       "610784                  Bullish  None   TSLA  \n",
       "571364                  Bullish  None   TSLA  \n",
       "8447                    Bullish  None   UBER  \n",
       "70872                   Bearish  None   TSLA  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twit_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTIMENT_COLUMN = 'entities.sentiment.basic'\n",
    "\n",
    "SENTIMENT_MAP = {\n",
    "    'Bullish': 1,\n",
    "    'Bearish': 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenized_corpus(twit_df):\n",
    "    tokenized_corpus = []\n",
    "    twit_ticker_pairs = list(zip(twit_df['body'], twit_df['ticker']))\n",
    "    \n",
    "    for twit, ticker in tqdm(twit_ticker_pairs):\n",
    "        tokenized = twit_tokenize(twit, ticker=ticker, normalize=True)\n",
    "        tokenized_corpus.append(tokenized)\n",
    "    \n",
    "    return tokenized_corpus\n",
    "\n",
    "def extract_target_values(twit_df):\n",
    "    return twit_df[SENTIMENT_COLUMN].map(SENTIMENT_MAP).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 314276/314276 [00:51<00:00, 6065.89it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 78570/78570 [00:12<00:00, 6329.67it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 98212/98212 [00:15<00:00, 6174.09it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_train = get_tokenized_corpus(twit_train_df)\n",
    "tokenized_val = get_tokenized_corpus(twit_val_df)\n",
    "tokenized_test = get_tokenized_corpus(twit_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = extract_target_values(twit_train_df)\n",
    "y_val = extract_target_values(twit_val_df)\n",
    "y_test = extract_target_values(twit_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([117634, 196642]), array([29491, 49079]), array([36803, 61409]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y_train), np.bincount(y_val), np.bincount(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(314276, (314276, 7), (314276,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_train), twit_train_df.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78570, (78570, 7), (78570,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_val), twit_val_df.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98212, (98212, 7), (98212,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_test), twit_test_df.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " ['$400', 'coming'],\n",
       " ['beautiful',\n",
       "  'looking',\n",
       "  'on',\n",
       "  'local',\n",
       "  'roads',\n",
       "  'city',\n",
       "  'seems',\n",
       "  'like',\n",
       "  'every',\n",
       "  'house',\n",
       "  'one',\n",
       "  'waiting',\n",
       "  'turn',\n",
       "  'on',\n",
       "  'model',\n",
       "  'standard',\n",
       "  'range',\n",
       "  'fit',\n",
       "  'families',\n",
       "  'needs',\n",
       "  'price',\n",
       "  'point'],\n",
       " ['guess', 'saudis', 'long', 'algos', 'activated', 'üòÅ', '‚ù§', 'Ô∏èüôèüèºüå∏üçªüí∞üé°ü•Ç'],\n",
       " ['wow',\n",
       "  'poor',\n",
       "  'bulls',\n",
       "  'buying',\n",
       "  'dips',\n",
       "  'calls',\n",
       "  'er',\n",
       "  'almost',\n",
       "  'got',\n",
       "  'suckered',\n",
       "  'buy',\n",
       "  'bs',\n",
       "  '200',\n",
       "  'easy',\n",
       "  'july']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy(doc):\n",
    "    return doc\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    tokenizer=dummy,\n",
    "    preprocessor=dummy,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=5,\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tfidf.fit_transform(tokenized_train)\n",
    "X_val = tfidf.transform(tokenized_val)\n",
    "X_test = tfidf.transform(tokenized_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((314276, 80179), (78570, 80179), (98212, 80179))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_list = tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_to_idx = dict(zip(vocab_list, range(len(vocab_list))))\n",
    "idx_to_vocab = funcy.flip(vocab_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab_to_feature_df(feature_vec, vocab_list):\n",
    "    df = pd.DataFrame(zip(vocab_list, feature_vec), columns=['vocab', 'score']).sort_values('score', ascending=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beautiful',\n",
       " 'looking',\n",
       " 'on',\n",
       " 'local',\n",
       " 'roads',\n",
       " 'city',\n",
       " 'seems',\n",
       " 'like',\n",
       " 'every',\n",
       " 'house',\n",
       " 'one',\n",
       " 'waiting',\n",
       " 'turn',\n",
       " 'on',\n",
       " 'model',\n",
       " 'standard',\n",
       " 'range',\n",
       " 'fit',\n",
       " 'families',\n",
       " 'needs',\n",
       " 'price',\n",
       " 'point']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vocab</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41483</th>\n",
       "      <td>looking on</td>\n",
       "      <td>0.279086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65411</th>\n",
       "      <td>standard range</td>\n",
       "      <td>0.263934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27442</th>\n",
       "      <td>families</td>\n",
       "      <td>0.246436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39928</th>\n",
       "      <td>like every</td>\n",
       "      <td>0.239116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55118</th>\n",
       "      <td>price point</td>\n",
       "      <td>0.234914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72944</th>\n",
       "      <td>turn on</td>\n",
       "      <td>0.232182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59170</th>\n",
       "      <td>roads</td>\n",
       "      <td>0.223286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28259</th>\n",
       "      <td>fit</td>\n",
       "      <td>0.221288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65409</th>\n",
       "      <td>standard</td>\n",
       "      <td>0.213022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50670</th>\n",
       "      <td>on model</td>\n",
       "      <td>0.209417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                vocab     score\n",
       "41483      looking on  0.279086\n",
       "65411  standard range  0.263934\n",
       "27442        families  0.246436\n",
       "39928      like every  0.239116\n",
       "55118     price point  0.234914\n",
       "72944         turn on  0.232182\n",
       "59170           roads  0.223286\n",
       "28259             fit  0.221288\n",
       "65409        standard  0.213022\n",
       "50670        on model  0.209417"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_to_feature_df(X_train[2].toarray().flatten(), vocab_list).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_score_df = vocab_to_feature_df(np.array(X_train.sum(axis=0)).flatten(), vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vocab</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50084</th>\n",
       "      <td>on</td>\n",
       "      <td>3681.619268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73723</th>\n",
       "      <td>up</td>\n",
       "      <td>3264.188054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68596</th>\n",
       "      <td>tesla</td>\n",
       "      <td>2716.681859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62465</th>\n",
       "      <td>short</td>\n",
       "      <td>2525.798327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14901</th>\n",
       "      <td>buy</td>\n",
       "      <td>2473.448083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30789</th>\n",
       "      <td>go</td>\n",
       "      <td>2371.623439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71076</th>\n",
       "      <td>today</td>\n",
       "      <td>2371.468902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31169</th>\n",
       "      <td>going</td>\n",
       "      <td>2354.359237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48703</th>\n",
       "      <td>not</td>\n",
       "      <td>2306.600466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11130</th>\n",
       "      <td>bears</td>\n",
       "      <td>2211.345551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45575</th>\n",
       "      <td>more</td>\n",
       "      <td>2184.765732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40764</th>\n",
       "      <td>lol</td>\n",
       "      <td>2133.423289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39744</th>\n",
       "      <td>like</td>\n",
       "      <td>2097.426105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62996</th>\n",
       "      <td>shorts</td>\n",
       "      <td>2073.579195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23257</th>\n",
       "      <td>down</td>\n",
       "      <td>2000.070968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51879</th>\n",
       "      <td>out</td>\n",
       "      <td>1932.647366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29903</th>\n",
       "      <td>get</td>\n",
       "      <td>1932.344302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66092</th>\n",
       "      <td>stock</td>\n",
       "      <td>1833.269925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70630</th>\n",
       "      <td>time</td>\n",
       "      <td>1760.228448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14321</th>\n",
       "      <td>bulls</td>\n",
       "      <td>1737.370919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        vocab        score\n",
       "50084      on  3681.619268\n",
       "73723      up  3264.188054\n",
       "68596   tesla  2716.681859\n",
       "62465   short  2525.798327\n",
       "14901     buy  2473.448083\n",
       "30789      go  2371.623439\n",
       "71076   today  2371.468902\n",
       "31169   going  2354.359237\n",
       "48703     not  2306.600466\n",
       "11130   bears  2211.345551\n",
       "45575    more  2184.765732\n",
       "40764     lol  2133.423289\n",
       "39744    like  2097.426105\n",
       "62996  shorts  2073.579195\n",
       "23257    down  2000.070968\n",
       "51879     out  1932.647366\n",
       "29903     get  1932.344302\n",
       "66092   stock  1833.269925\n",
       "70630    time  1760.228448\n",
       "14321   bulls  1737.370919"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_score_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Logistic Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from scipy.sparse import hstack, vstack\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C=1.0, solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seung-jae_bang/.virtualenvs/my_research/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_val_pred = lr.predict(X_val)\n",
    "\n",
    "# accuracy_score(y_val, y_val_pred), f1_score(y_val, y_val_pred)\n",
    "\n",
    "# print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.796755997230481, 0.8468461556167663)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_test_pred), f1_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.63      0.70     36803\n",
      "           1       0.80      0.90      0.85     61409\n",
      "\n",
      "    accuracy                           0.80     98212\n",
      "   macro avg       0.79      0.76      0.77     98212\n",
      "weighted avg       0.80      0.80      0.79     98212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df = vocab_to_feature_df(lr.coef_.flatten(), vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vocab</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11130</th>\n",
       "      <td>bears</td>\n",
       "      <td>10.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62996</th>\n",
       "      <td>shorts</td>\n",
       "      <td>9.298578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15729</th>\n",
       "      <td>calls</td>\n",
       "      <td>5.862485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62919</th>\n",
       "      <td>shorties</td>\n",
       "      <td>4.702733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80042</th>\n",
       "      <td>üöÄüöÄüöÄ</td>\n",
       "      <td>4.697823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80029</th>\n",
       "      <td>üöÄ</td>\n",
       "      <td>4.696454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79624</th>\n",
       "      <td>üèéüöÄ</td>\n",
       "      <td>4.456905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29188</th>\n",
       "      <td>fud</td>\n",
       "      <td>4.396343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13776</th>\n",
       "      <td>breakout</td>\n",
       "      <td>4.265959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28468</th>\n",
       "      <td>fly</td>\n",
       "      <td>4.234172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73535</th>\n",
       "      <td>undervalued</td>\n",
       "      <td>4.195648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32577</th>\n",
       "      <td>green</td>\n",
       "      <td>4.169148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63426</th>\n",
       "      <td>shorty</td>\n",
       "      <td>4.128867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49166</th>\n",
       "      <td>not sell</td>\n",
       "      <td>4.104305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11056</th>\n",
       "      <td>bear trap</td>\n",
       "      <td>4.042854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33623</th>\n",
       "      <td>haters</td>\n",
       "      <td>4.041235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>$400</td>\n",
       "      <td>4.016955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15909</th>\n",
       "      <td>calls up</td>\n",
       "      <td>3.925617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76367</th>\n",
       "      <td>weak hands</td>\n",
       "      <td>3.912178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30870</th>\n",
       "      <td>go bulls</td>\n",
       "      <td>3.906373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             vocab      score\n",
       "11130        bears  10.566667\n",
       "62996       shorts   9.298578\n",
       "15729        calls   5.862485\n",
       "62919     shorties   4.702733\n",
       "80042          üöÄüöÄüöÄ   4.697823\n",
       "80029            üöÄ   4.696454\n",
       "79624           üèéüöÄ   4.456905\n",
       "29188          fud   4.396343\n",
       "13776     breakout   4.265959\n",
       "28468          fly   4.234172\n",
       "73535  undervalued   4.195648\n",
       "32577        green   4.169148\n",
       "63426       shorty   4.128867\n",
       "49166     not sell   4.104305\n",
       "11056    bear trap   4.042854\n",
       "33623       haters   4.041235\n",
       "1398          $400   4.016955\n",
       "15909     calls up   3.925617\n",
       "76367   weak hands   3.912178\n",
       "30870     go bulls   3.906373"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coef_df.head(20)\n",
    "coef_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_non_zero_idxes_for_vocab(X_train, vocab):\n",
    "    idx = vocab_to_idx[vocab]\n",
    "    nonzero_idxes = np.nonzero(X_train[:, idx].toarray().flatten())[0]\n",
    "    return nonzero_idxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idxes = np.random.choice(get_non_zero_idxes_for_vocab(X_train, 'bulls'), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['$TSLA Going to get worse bulls. It‚Äôs got to go to $180',\n",
       "       '$TSLA Bulls two hole cards ...(1) Saudis; and (2) profitability in current quarter ... that could be crumbling fast!',\n",
       "       '$BYND ethan and his family would like to thank you for donation to buy his new mansion!! he and his family are going to have a really wonderful Christmas this year!! thanks again bulls -',\n",
       "       '$TSLA Muskie fooled the bulls but not the üêª',\n",
       "       '$TSLA bulls just get out rn. Clearly it was a bull Trap',\n",
       "       '$SBUX Let the bears have one day, onward for the bulls.üöÄ',\n",
       "       '$TSLA  Elon to Bulls: I‚Äôm inviting you to a Party at my Mansion. I invited a great COOK named Tim, and we will dine BUFFET style üòÜüòÜüòÜüöÄüöÄ',\n",
       "       '$BA Don&#39;t listen to all the Pumpers, they will Kill your cash today Bulls! Sometimes you have to know when to FOLD&#39;EM!!! üÉèüÄÑ Don&#39;t be so shallow and not see the Price action sentiment! Big money dumping on Retail Gophers - Go for anything! this is headed where it belongs! No way this plane is returning back to Flight this year or under the name 737Max don&#39;t be silly bulls! $AAL $LUV $UAL $TSLA need to make them an electric plane lol ... Down Goes Frazier!!! Happy Feetü§£üíÄüêß',\n",
       "       '$TSLA only 175 dollars down to go till this fraud is valued correctly .. get it yet bulls . You were scammed !',\n",
       "       '$TSLA Since Bulls always post short losses...how many billions have longs lost since the top? Or is that irrelevant? Yep...it is.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twit_train_df.iloc[sample_idxes]['body'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = vstack((X_train, X_val))\n",
    "y_all = np.concatenate((y_train, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all.shape, y_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = np.zeros(y_all.shape[0], dtype=int)\n",
    "splits[:X_train.shape[0]] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits.sum(), X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PredefinedSplit(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps.get_n_splits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in ps.split():\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_param_grid = {'C': [1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(LogisticRegression(), \n",
    "                           lr_param_grid, \n",
    "                           cv=ps,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_all, y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_param_grid = {'C': [1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(SVC(kernel='linear'), \n",
    "                           svm_param_grid, \n",
    "                           cv=ps,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_all, y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
