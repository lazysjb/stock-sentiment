{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import arrow\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "from util.file_util import StockTwitsFileReader\n",
    "from util.stocktwits_helper import (\n",
    "    get_est_market_datetime, get_daily_sentiment_count_df,\n",
    "    get_all_stocktwits_tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arrow.factory import ArrowParseWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable Arrow warnings per https://github.com/crsmithdev/arrow/issues/612\n",
    "warnings.simplefilter(\"ignore\", ArrowParseWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_twits_reader = StockTwitsFileReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = 'SHAK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2018-01-01'\n",
    "end_date = '2018-03-30'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = stock_twits_reader.read_twit_file_in_range(ticker, start_date, end_date, cols='default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_sentiment_df = get_daily_sentiment_count_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_est</th>\n",
       "      <th>created_at_est</th>\n",
       "      <th>mkt_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-01-01 21:14:58</td>\n",
       "      <td>2018-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-01-01 09:10:05</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>2018-01-01 06:48:49</td>\n",
       "      <td>2018-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>2018-01-02 23:43:30</td>\n",
       "      <td>2018-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>2018-01-02 21:44:31</td>\n",
       "      <td>2018-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>2018-01-02 21:43:55</td>\n",
       "      <td>2018-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>2018-01-02 21:43:48</td>\n",
       "      <td>2018-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>2018-01-02 18:42:51</td>\n",
       "      <td>2018-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>2018-01-02 15:51:06</td>\n",
       "      <td>2018-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>2018-01-02 11:42:02</td>\n",
       "      <td>2018-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>2018-01-03 23:48:03</td>\n",
       "      <td>2018-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>2018-01-03 21:42:05</td>\n",
       "      <td>2018-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>2018-01-03 20:30:31</td>\n",
       "      <td>2018-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>2018-01-03 19:12:06</td>\n",
       "      <td>2018-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>2018-01-03 18:27:28</td>\n",
       "      <td>2018-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>2018-01-03 18:25:56</td>\n",
       "      <td>2018-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>2018-01-03 17:54:39</td>\n",
       "      <td>2018-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>2018-01-03 17:44:07</td>\n",
       "      <td>2018-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>2018-01-03 17:14:20</td>\n",
       "      <td>2018-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>2018-01-03 16:30:02</td>\n",
       "      <td>2018-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>2018-01-03 16:23:17</td>\n",
       "      <td>2018-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>2018-01-03 16:15:59</td>\n",
       "      <td>2018-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>2018-01-03 15:44:28</td>\n",
       "      <td>2018-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>2018-01-03 15:22:25</td>\n",
       "      <td>2018-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>2018-01-03 14:42:45</td>\n",
       "      <td>2018-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>2018-01-03 14:40:34</td>\n",
       "      <td>2018-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>2018-01-03 14:36:26</td>\n",
       "      <td>2018-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>2018-01-03 14:05:08</td>\n",
       "      <td>2018-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>2018-01-03 13:58:35</td>\n",
       "      <td>2018-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>2018-01-03 13:57:47</td>\n",
       "      <td>2018-01-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      date_est       created_at_est    mkt_date\n",
       "0   2018-01-01  2018-01-01 21:14:58  2018-01-02\n",
       "1   2018-01-01  2018-01-01 09:10:05  2018-01-01\n",
       "2   2018-01-01  2018-01-01 06:48:49  2018-01-01\n",
       "3   2018-01-02  2018-01-02 23:43:30  2018-01-03\n",
       "4   2018-01-02  2018-01-02 21:44:31  2018-01-03\n",
       "5   2018-01-02  2018-01-02 21:43:55  2018-01-03\n",
       "6   2018-01-02  2018-01-02 21:43:48  2018-01-03\n",
       "7   2018-01-02  2018-01-02 18:42:51  2018-01-03\n",
       "8   2018-01-02  2018-01-02 15:51:06  2018-01-02\n",
       "9   2018-01-02  2018-01-02 11:42:02  2018-01-02\n",
       "10  2018-01-03  2018-01-03 23:48:03  2018-01-04\n",
       "11  2018-01-03  2018-01-03 21:42:05  2018-01-04\n",
       "12  2018-01-03  2018-01-03 20:30:31  2018-01-04\n",
       "13  2018-01-03  2018-01-03 19:12:06  2018-01-04\n",
       "14  2018-01-03  2018-01-03 18:27:28  2018-01-04\n",
       "15  2018-01-03  2018-01-03 18:25:56  2018-01-04\n",
       "16  2018-01-03  2018-01-03 17:54:39  2018-01-04\n",
       "17  2018-01-03  2018-01-03 17:44:07  2018-01-04\n",
       "18  2018-01-03  2018-01-03 17:14:20  2018-01-04\n",
       "19  2018-01-03  2018-01-03 16:30:02  2018-01-04\n",
       "20  2018-01-03  2018-01-03 16:23:17  2018-01-04\n",
       "21  2018-01-03  2018-01-03 16:15:59  2018-01-04\n",
       "22  2018-01-03  2018-01-03 15:44:28  2018-01-03\n",
       "23  2018-01-03  2018-01-03 15:22:25  2018-01-03\n",
       "24  2018-01-03  2018-01-03 14:42:45  2018-01-03\n",
       "25  2018-01-03  2018-01-03 14:40:34  2018-01-03\n",
       "26  2018-01-03  2018-01-03 14:36:26  2018-01-03\n",
       "27  2018-01-03  2018-01-03 14:05:08  2018-01-03\n",
       "28  2018-01-03  2018-01-03 13:58:35  2018-01-03\n",
       "29  2018-01-03  2018-01-03 13:57:47  2018-01-03"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['date_est', 'created_at_est', 'mkt_date']].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bearish</th>\n",
       "      <th>Bullish</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mkt_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-03</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-04</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-05</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-07</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-08</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-09</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Bearish  Bullish\n",
       "mkt_date                    \n",
       "2018-01-03      4.0      1.0\n",
       "2018-01-04      1.0      2.0\n",
       "2018-01-05      1.0      1.0\n",
       "2018-01-07      0.0      3.0\n",
       "2018-01-08      2.0      1.0\n",
       "2018-01-09      0.0      1.0\n",
       "2018-01-10      0.0      3.0\n",
       "2018-01-12      0.0      1.0\n",
       "2018-01-13      1.0      0.0\n",
       "2018-01-14      0.0      1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_sentiment_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save down sentiment time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2018-01-01'\n",
    "end_date = '2019-08-10'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run this only for new tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ticker_list = get_all_stocktwits_tickers()\n",
    "ticker_list = [\n",
    "    'UBER',  # Uber\n",
    "    'LYFT',  # Lyft\n",
    "    'WORK',  # Slack\n",
    "    'ZM',  # Zoom\n",
    "    'PINS',  # Pinterest\n",
    "    'CHWY',  # Chewy\n",
    "    'CRWD',  # Crowdstrike\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/seung-jae_bang/Personal/Research/Stock_Sentiment/data/Stocktwits/processed/sentiment_summary_prelim'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_dir = stock_twits_reader.get_root_dir()\n",
    "save_dir = os.path.join(root_dir, 'processed', 'sentiment_summary_prelim')\n",
    "save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/seung-jae_bang/Personal/Research/Stock_Sentiment/data/Stocktwits/processed/sentiment_summary_prelim/{ticker}_sentiment_summary.pkl'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_file_format = '{ticker}_sentiment_summary.pkl'\n",
    "save_path_format = os.path.join(save_dir, save_file_format)\n",
    "save_path_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run for UBER took 0.18884118795394897 mins\n",
      "Run for LYFT took 0.224221932888031 mins\n",
      "Run for WORK took 0.10459887981414795 mins\n",
      "Run for ZM took 0.10971521536509196 mins\n",
      "Run for PINS took 0.1195593516031901 mins\n",
      "Run for CHWY took 0.0748002012570699 mins\n",
      "Run for CRWD took 0.06573506593704223 mins\n"
     ]
    }
   ],
   "source": [
    "for t in ticker_list:\n",
    "    tic = time.time()\n",
    "    \n",
    "    raw_df = stock_twits_reader.read_twit_file_in_range(t, start_date, end_date, cols='default')\n",
    "    daily_sentiment_df = get_daily_sentiment_count_df(raw_df)\n",
    "    daily_sentiment_df.to_pickle(save_path_format.format(ticker=t))\n",
    "    \n",
    "    toc = time.time()\n",
    "    print('Run for {} took {} mins'.format(t, (toc - tic) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
