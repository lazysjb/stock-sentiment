{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from util.file_util import StockTwitsFileReader\n",
    "from util.stockdata_helper import get_nday_returns_for_ticker\n",
    "from nlp.twokenize import normalizeTextForTagger, tokenize\n",
    "from nlp.text_processor import (\n",
    "    token_is_cash_tag, token_is_punct, token_matches_ticker, twit_tokenize\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = '2017-01-01'\n",
    "end_date = '2019-08-10'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index Twits by Date / Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/Users/seung-jae_bang/Personal/Research/Stock_Sentiment/data/Stocktwits/processed/daily_twit_text/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "RENAME_MAP = {\n",
    "    'entities.sentiment.basic': 'sentiment_label',\n",
    "}\n",
    "SENTIMENT_LABEL_LIST = [\n",
    "    'Bullish',\n",
    "    'Bearish',\n",
    "]\n",
    "\n",
    "def collect_raw_twits_for_ticker(ticker,\n",
    "                                 start_date,\n",
    "                                 end_date, \n",
    "                                 save=True):\n",
    "    file_path = os.path.join(DATA_DIR,\n",
    "                             '{}_{}_{}.pkl'.format(ticker, start_date, end_date))\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        processed_df = pd.read_pickle(file_path)\n",
    "    else:\n",
    "        stock_twits_reader = StockTwitsFileReader()\n",
    "        raw_twit_df = stock_twits_reader.read_twit_file_in_range(ticker, \n",
    "                                                                 start_date, \n",
    "                                                                 end_date, \n",
    "                                                                 cols='default')\n",
    "        processed_df = raw_twit_df.rename(columns=RENAME_MAP)\n",
    "        processed_df = processed_df[processed_df['sentiment_label'].isin(SENTIMENT_LABEL_LIST)].copy()\n",
    "    \n",
    "        if save:\n",
    "            print('Saving result in: {}'.format(file_path))\n",
    "            processed_df.to_pickle(file_path)\n",
    "    \n",
    "    return processed_df\n",
    "\n",
    "def get_twit_and_return_df(ticker, \n",
    "                           start_date, \n",
    "                           end_date):\n",
    "    twit_df = collect_raw_twits_for_ticker(ticker,\n",
    "                                           start_date,\n",
    "                                           end_date)\n",
    "    twit_df = twit_df[['date_est', 'body', 'sentiment_label']].copy()\n",
    "    twit_df['date'] = pd.to_datetime(twit_df['date_est'])\n",
    "    \n",
    "    return_df = get_nday_returns_for_ticker(ticker, \n",
    "                                            start_date=start_date, \n",
    "                                            end_date=end_date)\n",
    "    one_day_shift_return = return_df.shift(1)\n",
    "    \n",
    "    merged = twit_df.set_index('date').merge(one_day_shift_return,\n",
    "                                             left_index=True,\n",
    "                                             right_index=True,).dropna()\n",
    "    merged['ticker'] = ticker\n",
    "    \n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all tickers with large twit count\n",
    "\n",
    "all_tickers = pickle.load(open('./ticker_at_least_10_median.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:20<00:00,  1.11it/s]\n"
     ]
    }
   ],
   "source": [
    "twit_dfs = []\n",
    "\n",
    "for t in tqdm(all_tickers):\n",
    "    twit_dfs.append(\n",
    "        get_twit_and_return_df(t, start_date, end_date))\n",
    "\n",
    "all_twit_df = pd.concat(twit_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# twit_dict = {}\n",
    "\n",
    "# for t in tqdm(all_tickers):\n",
    "#     twit_dict[t] = collect_raw_twits_for_ticker(t,\n",
    "#                                                 start_date,\n",
    "#                                                 end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_start = '2017-01-01'\n",
    "analysis_end = '2017-06-30'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_twit_df = all_twit_df[analysis_start:analysis_end].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_est</th>\n",
       "      <th>body</th>\n",
       "      <th>sentiment_label</th>\n",
       "      <th>adjusted close return</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-05-03</th>\n",
       "      <td>2017-05-03</td>\n",
       "      <td>$FB up a dollar</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>0.002099</td>\n",
       "      <td>FB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-02-03</th>\n",
       "      <td>2017-02-03</td>\n",
       "      <td>$WMT stick to the cheaper retail giants.</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>0.007096</td>\n",
       "      <td>WMT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-05-01</th>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>$AMD Met exp and raised guidance; storm should...</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>-0.023495</td>\n",
       "      <td>AMD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-10</th>\n",
       "      <td>2017-04-10</td>\n",
       "      <td>$GS</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>-0.003324</td>\n",
       "      <td>GS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-10</th>\n",
       "      <td>2017-03-10</td>\n",
       "      <td>$AMD Here&amp;#39;s a bit of historical data for t...</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>0.008321</td>\n",
       "      <td>AMD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              date_est                                               body  \\\n",
       "date                                                                        \n",
       "2017-05-03  2017-05-03                                    $FB up a dollar   \n",
       "2017-02-03  2017-02-03           $WMT stick to the cheaper retail giants.   \n",
       "2017-05-01  2017-05-01  $AMD Met exp and raised guidance; storm should...   \n",
       "2017-04-10  2017-04-10                                                $GS   \n",
       "2017-03-10  2017-03-10  $AMD Here&#39;s a bit of historical data for t...   \n",
       "\n",
       "           sentiment_label  adjusted close return ticker  \n",
       "date                                                      \n",
       "2017-05-03         Bullish               0.002099     FB  \n",
       "2017-02-03         Bullish               0.007096    WMT  \n",
       "2017-05-01         Bullish              -0.023495    AMD  \n",
       "2017-04-10         Bearish              -0.003324     GS  \n",
       "2017-03-10         Bullish               0.008321    AMD  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_twit_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenized_corpus(twit_df):\n",
    "    tokenized_corpus = []\n",
    "    twit_ticker_pairs = list(zip(twit_df['body'], twit_df['ticker']))\n",
    "    \n",
    "    for twit, ticker in tqdm(twit_ticker_pairs):\n",
    "        tokenized = twit_tokenize(twit, ticker=ticker, normalize=True)\n",
    "        tokenized_corpus.append(tokenized)\n",
    "    \n",
    "    return tokenized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 354386/354386 [00:53<00:00, 6633.74it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_corpus = get_tokenized_corpus(all_twit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy(doc):\n",
    "    return doc\n",
    "\n",
    "cv = CountVectorizer(\n",
    "    tokenizer=dummy,\n",
    "    preprocessor=dummy,\n",
    "    ngram_range=(1, 3),\n",
    "    min_df=50,\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_matrix = cv.fit_transform(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((354386, 7268), 354386, (354386, 5))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_matrix.shape, len(tokenized_corpus), all_twit_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_day_up_idxes = np.nonzero((all_twit_df['adjusted close return'] > 0).values)[0]\n",
    "next_day_down_idxes = np.nonzero((all_twit_df['adjusted close return'] < 0).values)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((193764,), (157131,))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_day_up_idxes.shape, next_day_down_idxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_scores = np.array(count_matrix[next_day_up_idxes].mean(axis=0)).squeeze()\n",
    "down_scores = np.array(count_matrix[next_day_down_idxes].mean(axis=0)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seung-jae_bang/.virtualenvs/my_research/lib/python3.6/site-packages/ipykernel_launcher.py:1: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "log_odds = np.log(up_scores / down_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_odds_df = pd.DataFrame(\n",
    "    {'score': log_odds,\n",
    "     'vocab': cv.get_feature_names()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (log_odds_df['score'] != np.inf) & (log_odds_df['score'] != -np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_odds_df_new = log_odds_df[mask].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>vocab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>3.815791</td>\n",
       "      <td>175+ 190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>2.896519</td>\n",
       "      <td>175+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>1.598728</td>\n",
       "      <td>baidu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>1.515949</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2504</th>\n",
       "      <td>1.502156</td>\n",
       "      <td>existing swing short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3622</th>\n",
       "      <td>1.476838</td>\n",
       "      <td>josh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>1.388382</td>\n",
       "      <td>@amd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.345069</td>\n",
       "      <td>#twtr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5129</th>\n",
       "      <td>1.339252</td>\n",
       "      <td>presentation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290</th>\n",
       "      <td>1.306786</td>\n",
       "      <td>dropbox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>1.301896</td>\n",
       "      <td>andrew left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3863</th>\n",
       "      <td>1.249054</td>\n",
       "      <td>limits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5601</th>\n",
       "      <td>1.221185</td>\n",
       "      <td>say buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>1.199206</td>\n",
       "      <td>andrew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6593</th>\n",
       "      <td>1.117310</td>\n",
       "      <td>toyota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>1.116109</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814</th>\n",
       "      <td>1.108265</td>\n",
       "      <td>computex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>1.102625</td>\n",
       "      <td>920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6656</th>\n",
       "      <td>1.081423</td>\n",
       "      <td>tuesday's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6152</th>\n",
       "      <td>1.071373</td>\n",
       "      <td>stock split</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4519</th>\n",
       "      <td>1.063405</td>\n",
       "      <td>nokia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3584</th>\n",
       "      <td>1.054131</td>\n",
       "      <td>ismf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4617</th>\n",
       "      <td>1.032152</td>\n",
       "      <td>oems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997</th>\n",
       "      <td>1.009679</td>\n",
       "      <td>wednesday's closing price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6996</th>\n",
       "      <td>1.009679</td>\n",
       "      <td>wednesday's closing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.994412</td>\n",
       "      <td>$1k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6109</th>\n",
       "      <td>0.989135</td>\n",
       "      <td>steve jobs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5117</th>\n",
       "      <td>0.986690</td>\n",
       "      <td>predicting wednesday's closing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1789</th>\n",
       "      <td>0.986690</td>\n",
       "      <td>community predicting wednesday's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5116</th>\n",
       "      <td>0.986690</td>\n",
       "      <td>predicting wednesday's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2766</th>\n",
       "      <td>-1.029002</td>\n",
       "      <td>frontier edition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6846</th>\n",
       "      <td>-1.073334</td>\n",
       "      <td>vega frontier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>-1.096864</td>\n",
       "      <td>$fas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1343</th>\n",
       "      <td>-1.109045</td>\n",
       "      <td>boycott</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2704</th>\n",
       "      <td>-1.112429</td>\n",
       "      <td>fomc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6072</th>\n",
       "      <td>-1.144428</td>\n",
       "      <td>starbucks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6071</th>\n",
       "      <td>-1.160537</td>\n",
       "      <td>star wars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>-1.165073</td>\n",
       "      <td>$nvda $tsla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2328</th>\n",
       "      <td>-1.174642</td>\n",
       "      <td>earnings growth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>-1.181422</td>\n",
       "      <td>1600x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6643</th>\n",
       "      <td>-1.198172</td>\n",
       "      <td>trump supporters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2706</th>\n",
       "      <td>-1.243635</td>\n",
       "      <td>foods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>-1.245653</td>\n",
       "      <td>$wfc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2720</th>\n",
       "      <td>-1.282198</td>\n",
       "      <td>forecasts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5400</th>\n",
       "      <td>-1.287120</td>\n",
       "      <td>refugees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7054</th>\n",
       "      <td>-1.320443</td>\n",
       "      <td>whole foods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5297</th>\n",
       "      <td>-1.358184</td>\n",
       "      <td>radeon vega</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6847</th>\n",
       "      <td>-1.388216</td>\n",
       "      <td>vega frontier edition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3374</th>\n",
       "      <td>-1.581040</td>\n",
       "      <td>howard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5867</th>\n",
       "      <td>-1.621831</td>\n",
       "      <td>shows sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2149</th>\n",
       "      <td>-1.644646</td>\n",
       "      <td>doe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5868</th>\n",
       "      <td>-1.662995</td>\n",
       "      <td>shows sell signal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6534</th>\n",
       "      <td>-1.662995</td>\n",
       "      <td>today shows sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5701</th>\n",
       "      <td>-1.662995</td>\n",
       "      <td>sell signal ta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>-1.778177</td>\n",
       "      <td>$99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6025</th>\n",
       "      <td>-2.024851</td>\n",
       "      <td>speculation existing pre-market</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2501</th>\n",
       "      <td>-2.070313</td>\n",
       "      <td>existing pre-market</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>-2.673414</td>\n",
       "      <td>$109.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5811</th>\n",
       "      <td>-2.961096</td>\n",
       "      <td>short $109.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>-3.022972</td>\n",
       "      <td>$109.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7264 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         score                             vocab\n",
       "489   3.815791                          175+ 190\n",
       "488   2.896519                              175+\n",
       "1077  1.598728                             baidu\n",
       "496   1.515949                               190\n",
       "2504  1.502156              existing swing short\n",
       "3622  1.476838                              josh\n",
       "741   1.388382                              @amd\n",
       "30    1.345069                             #twtr\n",
       "5129  1.339252                      presentation\n",
       "2290  1.306786                           dropbox\n",
       "896   1.301896                       andrew left\n",
       "3863  1.249054                            limits\n",
       "5601  1.221185                           say buy\n",
       "895   1.199206                            andrew\n",
       "6593  1.117310                            toyota\n",
       "472   1.116109                               154\n",
       "1814  1.108265                          computex\n",
       "720   1.102625                               920\n",
       "6656  1.081423                         tuesday's\n",
       "6152  1.071373                       stock split\n",
       "4519  1.063405                             nokia\n",
       "3584  1.054131                              ismf\n",
       "4617  1.032152                              oems\n",
       "6997  1.009679         wednesday's closing price\n",
       "6996  1.009679               wednesday's closing\n",
       "122   0.994412                               $1k\n",
       "6109  0.989135                        steve jobs\n",
       "5117  0.986690    predicting wednesday's closing\n",
       "1789  0.986690  community predicting wednesday's\n",
       "5116  0.986690            predicting wednesday's\n",
       "...        ...                               ...\n",
       "2766 -1.029002                  frontier edition\n",
       "6846 -1.073334                     vega frontier\n",
       "207  -1.096864                              $fas\n",
       "1343 -1.109045                           boycott\n",
       "2704 -1.112429                              fomc\n",
       "6072 -1.144428                         starbucks\n",
       "6071 -1.160537                         star wars\n",
       "240  -1.165073                       $nvda $tsla\n",
       "2328 -1.174642                   earnings growth\n",
       "479  -1.181422                             1600x\n",
       "6643 -1.198172                  trump supporters\n",
       "2706 -1.243635                             foods\n",
       "271  -1.245653                              $wfc\n",
       "2720 -1.282198                         forecasts\n",
       "5400 -1.287120                          refugees\n",
       "7054 -1.320443                       whole foods\n",
       "5297 -1.358184                       radeon vega\n",
       "6847 -1.388216             vega frontier edition\n",
       "3374 -1.581040                            howard\n",
       "5867 -1.621831                        shows sell\n",
       "2149 -1.644646                               doe\n",
       "5868 -1.662995                 shows sell signal\n",
       "6534 -1.662995                  today shows sell\n",
       "5701 -1.662995                    sell signal ta\n",
       "174  -1.778177                               $99\n",
       "6025 -2.024851   speculation existing pre-market\n",
       "2501 -2.070313               existing pre-market\n",
       "50   -2.673414                            $109.3\n",
       "5811 -2.961096                      short $109.3\n",
       "51   -3.022972                            $109.5\n",
       "\n",
       "[7264 rows x 2 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_odds_df_new.sort_values('score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
